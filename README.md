# ğŸ§  RAG-Pilot: Documentation Intelligence System

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
![RAG Pipeline](https://img.shields.io/badge/Architecture-RAG_Pipeline-blueviolet)

A production-grade Retrieval-Augmented Generation (RAG) system for querying technical documentation with precise, context-grounded responses using Gemini and FAISS.
## ğŸ“‚ Project Structure
``` bash
rag-pilot/
â”œâ”€â”€ app/ # Application code
â”‚ â”œâ”€â”€ app.py # CLI interface
â”‚ â”œâ”€â”€ rag_chain.py # Core RAG pipeline
â”‚ â””â”€â”€ init.py # Package initialization
â”‚
â”œâ”€â”€ config/ # Configuration files
â”‚ â”œâ”€â”€ settings.py # Main settings
â”‚ â””â”€â”€ logging.conf # Logging configuration
â”‚
â”œâ”€â”€ data/ # Documentation data
â”‚ â””â”€â”€ langchain/
â”‚ â”œâ”€â”€ processed/ # Processed chunks
â”‚ â””â”€â”€ raw/ # Original documents
â”‚
â”œâ”€â”€ scripts/ # Data processing scripts
â”‚ â”œâ”€â”€ scrape_docs.py # Documentation scraper
â”‚ â”œâ”€â”€ chunk.py # Text chunking
â”‚ â””â”€â”€ embed.py # Embedding generation
â”‚
â”œâ”€â”€ tests/ # Test suite
â”‚ â”œâ”€â”€ test_rag.py # RAG pipeline tests
â”‚ â”œâ”€â”€ test_retrieval.py # Retrieval tests
â”‚ â””â”€â”€ test_llm.py # LLM interaction tests
â”‚
â”œâ”€â”€ evaluation/ # Evaluation scripts
â”‚ â””â”€â”€ ragas_eval.py # RAGAS metrics
â”‚
â”œâ”€â”€ requirements.txt # Main dependencies
â”œâ”€â”€ LICENSE # MIT License
â””â”€â”€ README.md # This file
```
## ğŸŒŸ Features

- **Accurate Technical Answers**: Grounded in official documentation
- **Optimized Retrieval**: FAISS + MMR search with FastEmbed embeddings
- **Full Pipeline Visibility**: Debug mode shows retrieval scores and chunks
- **Production Ready**: Config validation and system health checks
- **Cost Efficient**: Local embeddings with optional cloud LLM

## ğŸ›  Tech Stack

| Component           | Implementation       | Alternatives       |
|---------------------|----------------------|--------------------|
| **Embeddings**      | FastEmbed (BGE-small)| OpenAI, Cohere     |
| **Vector Store**    | FAISS                | Chroma, Pinecone   |
| **LLM**            | Google Gemini Pro    | GPT-4, Claude      |
| **Framework**      | LangChain            | LlamaIndex         |
| **Evaluation**     | RAGAS                | Custom metrics     |

## ğŸ“… Project Phases

| Phase | Name                          | Status    | Key Deliverables                          |
|-------|-------------------------------|-----------|-------------------------------------------|
| 1     | Planning & Scope Finalization | âœ… Done   | Tech stack, Architecture diagram         |
| 2     | Data Ingestion & Embedding    | âœ… Done   | Processed chunks, FAISS index            |
| 3     | RAG Pipeline Implementation   | âœ… Done   | Working retrieval, Gemini integration    |
| 4     | Streamlit UI Development      | ğŸŸ¡ Active | Chat interface, Response formatting      |
| 5     | Evaluation & Optimization     | â³ Pending| RAGAS metrics, Performance tuning        |
| 6     | Deployment & Documentation    | â³ Pending| Live demo, Final README                  |
| 7     | Future Enhancements           | â³ Later  | Auth system, CLI version                 |

## ğŸ“¦ Installation

```bash
# Clone repository
git clone https://github.com/Arman001/rag-pilot.git
cd rag-pilot

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```

## ğŸš€ Usage
### CLI Interface
```bash
python -m app.app

> Ask a question (or 'exit'): Explain LangChain Expression Language
> Answer: LangChain Expression Language (LCEL) provides...
```

### Python API
```bash
from app.rag_chain import rag_pipeline

response = rag_pipeline.query("How to create custom agents?")
print(response)
```

## ğŸ—ï¸ Architecture

```mermaid
graph TD
    %% Data Flow
    A[Raw Docs: LangChain] --> B[Scrape/Clean\nBeautifulSoup]
    B --> C[Chunk Text\n512 tokens + 50 overlap]
    C --> D[Generate Embeddings\nBGE-small or FastEmbed]
    D --> E[Vector DB\nFAISS/ChromaDB]

    %% Query Flow
    F[User Query\nvia Streamlit] --> G[Embed Query]
    G --> H[Retrieve Top-3 Chunks\nHybrid: BM25 + Vector]
    H --> I[Inject into Prompt Template]
    I --> J[LLM Generation\nGemini Pro - Free Tier]
    J --> K[Format Response\nCitations + code blocks]
    K --> L[Streamlit UI Output]

    %% Evaluation
    H --> M[RAGAS Evaluation\nContext Precision]
    J --> N[RAGAS Evaluation\nFaithfulness]
    D --> O[Compare Embeddings\nBGE vs FastEmbed]

    %% Maintenance
    P[Monthly GitHub Action] --> Q[Re-scrape Docs]
    Q --> R[Re-embed Chunks]
    R --> E

    %% Grouping
    subgraph "Data Pipeline (Free)"
        A --> B --> C --> D --> E
    end
    subgraph "RAG Pipeline (Gemini)"
        F --> G --> H --> I --> J --> K --> L
    end
    subgraph "Evaluation"
        M & N & O
    end
    subgraph "Maintenance"
        P --> Q --> R --> E
    end

    %% Styling
    classDef data fill:#e6f3ff,stroke:#4682b4,color:black;
    classDef rag fill:#ffe6f2,stroke:#db7093,color:black;
    classDef eval fill:#e6ffe6,stroke:#2e8b57,color:black;
    classDef maint fill:#fff2cc,stroke:#ffa500,color:black;
    class A,B,C,D,E data;
    class F,G,H,I,J,K,L rag;
    class M,N,O eval;
    class P,Q,R maint;
	
```
## ğŸ¤ Contributing
1. Fork the repository
2. Create your feature branch:

``` bash
git checkout -b feature/your-feature
```
2. Commit changes:

```bash
git commit -m 'Add some feature'
```
3. Push to branch:

``` bash
git push origin feature/your-feature
```

## ğŸ“œ License

Distributed under the MIT License.

## âœ‰ï¸ Contact
**Website**: [muhammadsaad.dev](https://www.muhammadsaad.dev/)
**Email**: hell@muhammadsaad.dev
